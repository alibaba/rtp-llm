# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2023-2025, RTP-LLM
# This file is distributed under the same license as the RTP-LLM package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2025.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: RTP-LLM 0.2.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-09-24 14:39+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: zh_CN\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.17.0\n"

#: ../../backend/Multimodal.md:1
msgid "Multimodal Part Debug and Separate Deployment"
msgstr "多模态部分调试与独立部署"

#: ../../backend/Multimodal.md:3
msgid "Multimodal Development"
msgstr "多模态开发"

#: ../../backend/Multimodal.md:5
msgid ""
"A multimodal model refers to an LLM that incorporates multimodal inputs. "
"Currently, the primary input format is URLs, which are distinguished by "
"specific placeholders using OpenAI formatting. Each multimodal model has "
"its unique preprocessing pipeline but must implement the following "
"interfaces:"
msgstr "多模态模型是指包含多模态输入的LLM。目前，主要的输入格式是URL，通过使用OpenAI格式的特定占位符进行区分。每个多模态模型都有其独特的预处理管道，但必须实现以下接口："

#: ../../backend/Multimodal.md:7
msgid ""
"The multimodal model must inherit from `MultimodalMixin` in "
"`rtp_llm/models/multimodal/multimodal_mixin.py` and instantiate `mm_part`"
" as the processing class for multimodal inputs."
msgstr "多模态模型必须继承自 `rtp_llm/models/multimodal/multimodal_mixin.py` 中的 `MultimodalMixin`，并实例化 `mm_part` 作为多模态输入的处理类。"

#: ../../backend/Multimodal.md:9
msgid ""
"`mm_part` has various interface implementations based on input types, "
"such as images, videos, or audio. The logic must be self-consistent, with"
" the most critical interfaces being `mm_embedding`, `_mm_preprocess`, and"
" `mm_process`:"
msgstr "`mm_part` 根据输入类型有不同的接口实现，例如图像、视频或音频。逻辑必须保持一致，最关键接口是 `mm_embedding`、`_mm_preprocess` 和 `mm_process`："

#: ../../backend/Multimodal.md:11
msgid ""
"`mm_embedding` has a default implementation that calls `_mm_preprocess` "
"and `mm_process`, converting the multimodal input URL into an embedding "
"tensor and other information (e.g., position IDs)."
msgstr "`mm_embedding` 有默认实现，它调用 `_mm_preprocess` 和 `mm_process`，将多模态输入URL转换为嵌入张量和其他信息（例如，位置ID）。"

#: ../../backend/Multimodal.md:13
msgid ""
"`_mm_preprocess` also has default implementations for specific "
"modalities, preprocessing byte data from input url and preparing inputs "
"for mm_process. This separation is necessary because preprocessing is "
"CPU-bound, while subsequent processing is GPU-bound."
msgstr "`_mm_preprocess` 对于特定模态也有默认实现，对输入URL中的字节数据进行预处理并为mm_process准备输入。这种分离是必要的，因为预处理是CPU密集型的，而后续处理是GPU密集型的。"

#: ../../backend/Multimodal.md:15
msgid ""
"`mm_process` handles GPU-based transformation of preprocessed inputs into"
" outputs."
msgstr "`mm_process` 处理预处理输入到输出的基于GPU的转换。"

#: ../../backend/Multimodal.md:17
msgid ""
"For model weights, the required weights must be registered in "
"`GptInitModelParameters` under `mm_related_params.vit_weights`. Refer to "
"`BaseVitWeights` for specific implementation logic."
msgstr "对于模型权重，所需的权重必须在 `GptInitModelParameters` 下的 `mm_related_params.vit_weights` 中注册。具体实现逻辑请参考 `BaseVitWeights`。"

#: ../../backend/Multimodal.md:19
msgid "Debug"
msgstr "调试"

#: ../../backend/Multimodal.md:21
msgid "Start multimodal part."
msgstr "启动多模态部分。"

#: ../../backend/Multimodal.md:32
msgid "Start a grpc client."
msgstr "启动grpc客户端。"

#: ../../backend/Multimodal.md:80
msgid "hints: Grpc port is START_PORT + 1."
msgstr "提示：Grpc端口是 START_PORT + 1。"

