# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2023-2025, RTP-LLM
# This file is distributed under the same license as the RTP-LLM package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2025.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: RTP-LLM 0.2.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-10-09 17:27+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: zh_CN\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.17.0\n"

#: ../../backend/lora.ipynb:9
msgid "LoRA Serving"
msgstr ""

#: ../../backend/lora.ipynb:20
msgid ""
"RTP-LLM supports **Static LoRA** and **Dynamic LoRA** inference modes. "
"For information on LoRA principles, refer to `Hugging Face Official "
"Documentation "
"<https://huggingface.co/docs/peft/conceptual_guides/lora>`__."
msgstr ""

#: ../../backend/lora.ipynb:32
msgid "Serving Single Adaptor（Static LoRA）"
msgstr ""

#: ../../backend/lora.ipynb:35 ../../backend/lora.ipynb:147
msgid "Feature"
msgstr ""

#: ../../backend/lora.ipynb:35 ../../backend/lora.ipynb:147
msgid "Description"
msgstr ""

#: ../../backend/lora.ipynb:37 ../../backend/lora.ipynb:149
msgid "**Fusion Method**"
msgstr ""

#: ../../backend/lora.ipynb:37
msgid ""
"Before inference, the base model and specified LoRA weights are "
"**permanently fused** (irreversible)."
msgstr ""

#: ../../backend/lora.ipynb:39 ../../backend/lora.ipynb:151
msgid "**Applicable Scenarios**"
msgstr ""

#: ../../backend/lora.ipynb:39
msgid "Scenarios requiring **single LoRA** with pursuit of optimal performance."
msgstr ""

#: ../../backend/lora.ipynb:41 ../../backend/lora.ipynb:153
msgid "**Limitations**"
msgstr ""

#: ../../backend/lora.ipynb:41
msgid ""
"After fusion, the base model cannot be restored; the original output "
"before applying LoRA cannot be obtained simultaneously."
msgstr ""

#: ../../backend/lora.ipynb:45 ../../backend/lora.ipynb:157
msgid "Usage"
msgstr ""

#: ../../backend/lora.ipynb:47
msgid ""
"When the startup parameter ``--lora_info`` contains only **1 element**, "
"it automatically enters static mode."
msgstr ""

#: ../../backend/lora.ipynb:48
#, python-brace-format
msgid ""
"Example: ``--lora_info "
"{\"test0\":\"/mnt/nas1/lora/taoshang_qwen_lora_18000/lora\"}``"
msgstr ""

#: ../../backend/lora.ipynb:144
msgid "Serving Multiple Adaptors(Dynamic LoRA)"
msgstr ""

#: ../../backend/lora.ipynb:149
msgid ""
"Load LoRA dynamically as a plugin during inference, **without modifying "
"base weights**."
msgstr ""

#: ../../backend/lora.ipynb:151
msgid ""
"Scenarios requiring **multiple LoRA switching** or **dynamic selection by"
" request**."
msgstr ""

#: ../../backend/lora.ipynb:153
msgid "Only some models support LoRA"
msgstr ""

#: ../../backend/lora.ipynb:159
msgid ""
"Specify the LoRA to be used for this request through "
"``generate_config.adapter_name``."
msgstr ""

#: ../../backend/lora.ipynb:160
msgid "Field rules"
msgstr ""

#: ../../backend/lora.ipynb:161
msgid "Type: ``str`` or ``list[str]``"
msgstr ""

#: ../../backend/lora.ipynb:162
msgid ""
"The number of elements and order must be **completely aligned** with "
"``prompt``"
msgstr ""

#: ../../backend/lora.ipynb:163
msgid "Leave empty or omit to indicate **not using LoRA**"
msgstr ""

#: ../../backend/lora.ipynb:164
msgid ""
"When the startup parameter ``--lora_info`` contains **multiple** "
"elements, it automatically enters dynamic mode."
msgstr ""

#: ../../backend/lora.ipynb:165
#, python-brace-format
msgid ""
"Example: ``--lora_info "
"{\"test0\":\"/mnt/nas1/lora/qwen_lora_18000/lora\", "
"\"test1\":\"/mnt/nas1/lora/qwen_lora_18000/lora\"}``"
msgstr ""

