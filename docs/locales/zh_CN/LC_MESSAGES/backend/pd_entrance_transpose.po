# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2023-2025, RTP-LLM
# This file is distributed under the same license as the RTP-LLM package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2025.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: RTP-LLM 0.2.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-10-09 17:27+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: zh_CN\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.17.0\n"

#: ../../backend/pd_entrance_transpose.md:1
msgid "PD Disaggregation Transpose"
msgstr ""

#: ../../backend/pd_entrance_transpose.md:3
msgid "Background"
msgstr ""

#: ../../backend/pd_entrance_transpose.md:5
msgid ""
"The PD disaggregation implementation defaults to using the Prefill node "
"as the request entry point. After the Prefill instance computes the first"
" token, it needs to transfer the KV cache to the Decode instance. "
"Subsequent token generation is completed on the Decode instance, and the "
"results are streamed back to the user through the Prefill instance. In "
"fact, the Prefill inference work is completed after computing the first "
"token and transferring the KV Cache to the Decode instance. However, in "
"the scenario where Prefill is the front-end stream receiver, the instance"
" still needs to act as a relay to return the tokens output by the Decode "
"instance to the user."
msgstr ""

#: ../../backend/pd_entrance_transpose.md:7
msgid ""
"To solve this problem, RTP-LLM provides the capability of PD "
"disaggregation stream receiver inversion, that is, making the Decode "
"instance the request entry point. In the Decode front-end stream "
"receiving implementation, the Decode instance will send an async "
"loadCache RPC request to the Prefill instance. After receiving the "
"request, the Prefill instance will start the first token computation, and"
" the generated KV cache will be transmitted in units of model layers. "
"Each time a layer's KV cache computation is completed, the Prefill "
"instance will call the transfer RPC interface of the Decode instance to "
"let it use RDMA read to read the corresponding KV cache block from the "
"Prefill instance. After the KV Cache is fully loaded, the Decode instance"
" will compute subsequent tokens locally and stream the results back to "
"the user."
msgstr ""

#: ../../backend/pd_entrance_transpose.md:9
msgid "Configuration"
msgstr ""

#: ../../backend/pd_entrance_transpose.md:11
msgid ""
"Currently, PD inversion is disabled by default in production. If you need"
" to enable the PD inversion stream receiving capability, you need to "
"configure the following environment variables when starting the "
"Decode/Prefill instances:"
msgstr ""

