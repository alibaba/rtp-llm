# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2023-2025, RTP-LLM
# This file is distributed under the same license as the RTP-LLM package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2025.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: RTP-LLM 0.2.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-09-12 17:38+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: zh_CN\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.17.0\n"

#: ../../backend/af_disaggregation.md:1
msgid "Attention FFN Disaggregation (AFD)"
msgstr "注意力FFN解聚(AFD)"

#: ../../backend/af_disaggregation.md:3
msgid ""
"Attention FFN Disaggregation is a technique that separates the attention "
"and feed-forward network (FFN) computations in transformer models to "
"optimize performance. Currently, this feature only supports Qwen3 dense "
"models (Qwen3-32B and Qwen3-8B), with support for MOE versions planned "
"for future releases."
msgstr "注意力FFN解聚是一种将Transformer模型中的注意力和前馈网络(FFN)计算分离以优化性能的技术。目前该功能仅支持Qwen3稠密模型(Qwen3-32B和Qwen3-8B)，对MOE版本的支持计划在未来的版本中提供。"

#: ../../backend/af_disaggregation.md:5
msgid "Example launch Command"
msgstr "启动命令示例"

#: ../../backend/af_disaggregation.md:20
msgid "Supported models"
msgstr "支持的模型"

#: ../../backend/af_disaggregation.md:22
msgid "Below the supported models are summarized in a table."
msgstr "以下表格总结了支持的模型。"

#: ../../backend/af_disaggregation.md:24
msgid ""
"If you are unsure if a specific architecture is implemented, you can "
"search for it via GitHub. For example, to search for `Qwen3ForCausalLM`, "
"use the expression:"
msgstr "如果您不确定某个特定架构是否已实现，可以通过GitHub搜索。例如，要搜索`Qwen3ForCausalLM`，请使用以下表达式："

#: ../../backend/af_disaggregation.md:30
msgid "in the GitHub search bar."
msgstr "在GitHub搜索栏中。"

#: ../../backend/af_disaggregation.md
msgid "Model Family (Variants)"
msgstr "模型系列(变体)"

#: ../../backend/af_disaggregation.md
msgid "Example HuggingFace Identifier"
msgstr "HuggingFace标识符示例"

#: ../../backend/af_disaggregation.md
msgid "ModelType"
msgstr "模型类型"

#: ../../backend/af_disaggregation.md
msgid "Description"
msgstr "描述"

#: ../../backend/af_disaggregation.md
msgid "**Qwen** (3 series)"
msgstr "**Qwen**(3系列)"

#: ../../backend/af_disaggregation.md
msgid "`Qwen/Qwen3-32B`, `Qwen/Qwen3-8B`"
msgstr "`Qwen/Qwen3-32B`、`Qwen/Qwen3-8B`"

#: ../../backend/af_disaggregation.md
msgid "qwen_3"
msgstr "qwen_3"

#: ../../backend/af_disaggregation.md
msgid ""
"Alibaba's latest Qwen3 series for complex reasoning, language "
"understanding, and generation tasks; Currently supports dense variants "
"(Qwen3-32B and Qwen3-8B) with AFD. MOE versions will be supported in "
"future releases."
msgstr "阿里巴巴最新的Qwen3系列，适用于复杂推理、语言理解和生成任务；目前支持使用AFD的稠密变体(Qwen3-32B和Qwen3-8B)。MOE版本将在未来版本中支持。"

