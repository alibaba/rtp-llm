# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2023-2025, RTP-LLM
# This file is distributed under the same license as the RTP-LLM package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2025.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: RTP-LLM 0.2.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-09-24 14:39+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: zh_CN\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.17.0\n"

#: ../../benchmark/benchmark.md:1
msgid "RTP-LLM Performance Benchmark Tool"
msgstr "RTP-LLM 性能基准测试工具"

#: ../../benchmark/benchmark.md:2
msgid ""
"In this chapter, I will present the performance testing tools developed "
"in RTP-LLM, including standalone measurement of model prefill and decode "
"performance under various batch sizes with single-node and multi-node "
"parallelism, timeline recording, and their usage methods."
msgstr "在本章节中，我将介绍RTP-LLM中开发的性能测试工具，包括在各种批次大小下对模型预填充和解码性能的独立测量，支持单节点和多节点并行，时间线记录，以及它们的使用方法。"

#: ../../benchmark/benchmark.md:3
msgid "Design Principle"
msgstr "设计原理"

#: ../../benchmark/benchmark.md:4
msgid ""
"RTP-LLM employs a special batch scheduler that accumulates requests until"
" the specified batch size is reached, then all requests enter the engine "
"simultaneously. The scheduler supports both prefill and decode modes; in "
"decode mode, requests are only allocated KV cache without prefill, "
"enabling accurate and efficient measurement of engine performance. In "
"detail, the batch-scheduler profiler is executed three times for a single"
" input:"
msgstr "RTP-LLM采用特殊的批次调度器，它会累积请求直到达到指定的批次大小，然后所有请求同时进入引擎。调度器支持预填充和解码两种模式；在解码模式下，请求只分配KV缓存而不进行预填充，从而实现准确高效的引擎性能测量。具体来说，批次调度器分析器对单个输入执行三次："

#: ../../benchmark/benchmark.md:6
msgid "Warm-up run, to account for one-time setup such as JIT compilation."
msgstr "预热运行，用于处理一次性设置，如JIT编译。"

#: ../../benchmark/benchmark.md:7
msgid "Timing run, to measure engine performance."
msgstr "计时运行，用于测量引擎性能。"

#: ../../benchmark/benchmark.md:8
msgid ""
"Profiling run, to capture a timeline for subsequent analysis; this step "
"may degrade end-to-end performance."
msgstr "性能分析运行，用于捕获时间线以供后续分析；此步骤可能会降低端到端性能。"

#: ../../benchmark/benchmark.md:10
msgid ""
"For every run we use min_new_tokens and max_new_tokens to ensure that all"
" requests perform the same number of decode steps."
msgstr "对于每次运行，我们使用min_new_tokens和max_new_tokens来确保所有请求执行相同数量的解码步骤。"

#: ../../benchmark/benchmark.md:12
msgid ""
"Since in decode mode, we not prefill the KVCache, so hidden_states after "
"every forward step is not real. So we also hack moe gate select for moe "
"model and speculative accept func for mtp. In that way, we get stable "
"result for analyse result."
msgstr "由于在解码模式下，我们不预填充KVCache，所以每个前向步骤后的hidden_states不是真实的。因此我们还对MoE模型的gate选择函数和MTP的speculative accept函数进行了修改。通过这种方式，我们获得了稳定的分析结果。"

#: ../../benchmark/benchmark.md:13
msgid "Single-Node Benchmark"
msgstr "单节点基准测试"

#: ../../benchmark/benchmark.md:14
msgid ""
"using commands below can start a performance benchmark, mixed prefill and"
" decode"
msgstr "使用以下命令可以启动性能基准测试，混合预填充和解码"

#: ../../benchmark/benchmark.md:27
msgid ""
"specially `batch_size` states for the batch in single DP node, when "
"`DP_SIZE` param is setted."
msgstr "特别地，当设置了`DP_SIZE`参数时，`batch_size`表示单个DP节点中的批次大小。"

#: ../../benchmark/benchmark.md:29
#, python-brace-format
msgid ""
"also we support test prefill or decode only when prefill and decode not "
"share the same config(such as prefill use deepep normal, and decode use "
"deepep masked), in that case user should also set "
"`--partial={0:all(default), 1:decode, 2:prefill}`, below is an example of"
" testing decode only:"
msgstr "当预填充和解码不共享相同配置时（例如预填充使用deepep normal，解码使用deepep masked），我们也支持仅测试预填充或解码，在这种情况下，用户还应设置`--partial={0:all(default), 1:decode, 2:prefill}`，以下是仅测试解码的示例："

#: ../../benchmark/benchmark.md:33
msgid "Multi Node Benchmark"
msgstr "多节点基准测试"

#: ../../benchmark/benchmark.md:34
msgid ""
"We also provide a Python script to enable multi-node benchmark, but since"
" it requires setting up the environment and starting the script on "
"multiple machines, it still involves more steps than single-node testing."
msgstr "我们还提供了一个Python脚本来启用多节点基准测试，但由于需要在多台机器上设置环境并启动脚本，它仍然比单节点测试涉及更多步骤。"

#: ../../benchmark/benchmark.md:36
msgid ""
"For each machine to be tested, you need to create an environment in which"
" RTP-LLM can run and support passwordless SSH access from the current "
"machine's port."
msgstr "对于每台要测试的机器，您需要创建一个RTP-LLM可以运行并支持从当前机器端口进行无密码SSH访问的环境。"

#: ../../benchmark/benchmark.md:37
msgid "Benchmark Yaml"
msgstr "基准测试Yaml配置"

#: ../../benchmark/benchmark.md:38
msgid ""
"Configure the parameters with reference to "
"`rtp_llm/test/perf_test/multi_node/multi_benchmark_config.yaml`. Below is"
" the detail explaination of yaml structure."
msgstr "参考`rtp_llm/test/perf_test/multi_node/multi_benchmark_config.yaml`配置参数。以下是yaml结构的详细说明。"

#: ../../benchmark/benchmark.md:40
msgid ""
"First part is for cloning code to local in ssh machine, and checkout to "
"the branch you need to test"
msgstr "第一部分用于在SSH机器上将代码克隆到本地，并检出到您需要测试的分支"

#: ../../benchmark/benchmark.md:48
msgid "Second part describe the machine list, user name and port to ssh"
msgstr "第二部分描述机器列表、用户名和SSH端口"

#: ../../benchmark/benchmark.md:60
msgid ""
"Third part describe the model info which should be pre-download to local "
"machine"
msgstr "第三部分描述应预下载到本地机器的模型信息"

#: ../../benchmark/benchmark.md:66
msgid ""
"Fourth part describe the test cases, including prefill/decode, batch_size"
" and input_len(they will be used as Cartesian product).Specially, tp_size"
" and dp_size len should be equal as each tuple of them will be started as"
" a parallel config. For example, in below config, script will start three"
" server with `TP=1 DP=32`, `TP=2 DP=16`, `TP=4 DP=8` and benchmark"
msgstr "第四部分描述测试用例，包括预填充/解码、batch_size和input_len（它们将用作笛卡尔积）。特别地，tp_size和dp_size的长度应该相等，因为它们的每个元组将作为并行配置启动。例如，在下面的配置中，脚本将启动三个服务器，配置为`TP=1 DP=32`、`TP=2 DP=16`、`TP=4 DP=8`并进行基准测试"

#: ../../benchmark/benchmark.md:75
msgid ""
"bazel_build_args is the flag for bazelisk build, if you want to test in "
"AMD card, change `--config=rocm`"
msgstr "bazel_build_args是bazelisk构建的标志，如果您想在AMD卡上测试，请将`--config=rocm`"

#: ../../benchmark/benchmark.md:82
msgid ""
"last part is the model env config, be careful that all env configs type "
"should in `[int, float, string, bool]`, or there maybe unexpected error"
msgstr "最后一部分是模型环境配置，请注意所有环境配置类型应在`[int, float, string, bool]`中，否则可能会出现意外错误"

#: ../../benchmark/benchmark.md:104
msgid "Run step"
msgstr "运行步骤"

#: ../../benchmark/benchmark.md:116
msgid ""
"Also, multi-node benchmark dumps profile json in rank0, but currently we "
"don't scp dir to local yet. So please go to rank0 and get profile data "
"manually before clean step"
msgstr "另外，多节点基准测试在rank0中转储profile json，但目前我们还没有将目录scp到本地。所以在清理步骤之前，请手动到rank0获取profile数据"

#: ../../benchmark/benchmark.md:118
msgid "Result Format"
msgstr "结果格式"

#: ../../benchmark/benchmark.md:119
msgid "Decode result, where batch size stands for per DP Rank"
msgstr "解码结果，其中批次大小表示每个DP Rank的批次"

