# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2023-2025, RTP-LLM
# This file is distributed under the same license as the RTP-LLM package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2025.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: RTP-LLM 0.2.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-09-12 17:38+0800\n"
"PO-Revision-Date: 2025-09-12 17:38+0800\n"
"Last-Translator: Claude <noreply@anthropic.com>\n"
"Language: zh_CN\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.17.0\n"

#: ../../Tokenizer.md:1
msgid "Tokenizer和Openai Renderer"
msgstr "Tokenizer和Openai Renderer"

#: ../../Tokenizer.md:3
msgid ""
"目前rtp_llm的tokenizer和openai "
"renderer均为独立注册，和model_type绑定，具有统一接口。注意，这里的model_type需要和模型注册时完全一致。"
msgstr ""
"目前rtp_llm的tokenizer和openai "
"renderer均为独立注册，和model_type绑定，具有统一接口。注意，这里的model_type需要和模型注册时完全一致。"
""

#: ../../Tokenizer.md:5
msgid ""
"Tokenizer主要是把`transformers.AutoTokenizer`包了一层，以便进行模型相关的自定义tokenizer行为；对应的，Openai"
" renderer是为了执行自定义Openai行为。"
msgstr ""
"Tokenizer主要是把`transformers.AutoTokenizer`包了一层，以便进行模型相关的自定义tokenizer行为；对应的，Openai"
" renderer是为了执行自定义Openai行为。"
""

#: ../../Tokenizer.md:7
msgid "开发指南"
msgstr "开发指南"

#: ../../Tokenizer.md:9
msgid ""
"对tokenizer而言，在`rtp_llm/frontend/tokenizer_factory/tokenizers/`目录下继承BaseTokenizer实现对应模型相关tokenize逻辑即可，用register_tokenizer进行注册，可以参考目录下多种tokenizer实现。具体需要实现的接口由需求决定，一般只用修改encode和decode两个接口即可。注意，引擎的返回结果为流式输出，如遇到多个token"
" id共同拼成一个字符的情况会等待下一个token id一起输出。"
msgstr ""
"对tokenizer而言，在`rtp_llm/frontend/tokenizer_factory/tokenizers/`目录下继承BaseTokenizer实现对应模型相关tokenize逻辑即可，用register_tokenizer进行注册，可以参考目录下多种tokenizer实现。具体需要实现的接口由需求决定，一般只用修改encode和decode两个接口即可。注意，引擎的返回结果为流式输出，如遇到多个token"
" id共同拼成一个字符的情况会等待下一个token id一起输出。"
""

#: ../../Tokenizer.md:11
msgid ""
"对于openai_renderer而言，主要是用来解析openai格式的输入，并渲染成正常的string格式输入。需要继承CustomChatRenderer并实现render_chat接口，由请求到渲染出来的各种输入，对于多模态模型而言需要手动将多模态输入剥离单独处理，因此每个模型都需要单独实现其openai"
" renderer。"
msgstr ""
"对于openai_renderer而言，主要是用来解析openai格式的输入，并渲染成正常的string格式输入。需要继承CustomChatRenderer并实现render_chat接口，由请求到渲染出来的各种输入，对于多模态模型而言需要手动将多模态输入剥离单独处理，因此每个模型都需要单独实现其openai"
" renderer。"
""

