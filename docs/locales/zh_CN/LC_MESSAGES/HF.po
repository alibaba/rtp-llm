# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2023-2025, RTP-LLM
# This file is distributed under the same license as the RTP-LLM package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2025.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: RTP-LLM 0.2.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-09-12 17:38+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: zh_CN\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.17.0\n"

#: ../../HF.md:1
msgid "Loading Huggingface Models"
msgstr "加载Huggingface模型"

#: ../../HF.md:3
msgid ""
"Huggingface models support downloading models remotely by model name. The"
" code is as follows: (If you cannot access Huggingface, you need to "
"configure the environment variable `HF_ENDPOINT`)"
msgstr "Huggingface模型支持通过模型名称远程下载模型。代码如下：（如果您无法访问Huggingface，需要配置环境变量`HF_ENDPOINT`）"

#: ../../HF.md:15
msgid ""
"The prompt format in the pipeline is the Qwen model's prompt format. You "
"need to replace it with your model's prompt format."
msgstr "管道中的提示格式是Qwen模型的提示格式。您需要将其替换为您模型的提示格式。"

#: ../../HF.md:17
msgid "It also supports loading through model path"
msgstr "它也支持通过模型路径加载"

#: ../../HF.md:21
msgid ""
"When building the model, basic configuration parameters are used by "
"default. You can also modify the configuration by building `ModelConfig`."
" The introduction to `ModelConfig` parameters is in the next section."
msgstr "在构建模型时，默认使用基本配置参数。您也可以通过构建`ModelConfig`来修改配置。`ModelConfig`参数的介绍在下一节。"

#: ../../HF.md:32
msgid ""
"If there are cases where the framework cannot infer the model type but "
"the implementation has already been adapted, you can specify the model "
"type manually"
msgstr "如果存在框架无法推断模型类型但实现已经适配的情况，您可以手动指定模型类型"

