# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2023-2025, RTP-LLM
# This file is distributed under the same license as the RTP-LLM package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: RTP-LLM 0.2.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-09-19 11:21+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../../supported_models/support_new_models.md:1
msgid "How to Support New Models"
msgstr ""

#: ../../supported_models/support_new_models.md:3
msgid "This document explains how to add support for new language models and multimodal large language models (MLLMs) in RTP-LLM. It also covers how to test new models and register external implementations."
msgstr ""

#: ../../supported_models/support_new_models.md:6
msgid "How to Support a New Language Model"
msgstr ""

#: ../../supported_models/support_new_models.md:8
msgid "To support a new model in RTP-LLM, you only need to add a single file under the [RTP-LLM Models Directory](http://gitlab.alibaba-inc.com/foundation_models/RTP-LLM/tree/main/rtp_llm/models_py/). You can learn from existing model implementations and create a new file for your model. For most models, you should be able to find a similar model to start with (e.g., starting from Llama). Also refer how to [port a Model from vLLM to RTP-LLM](#port-a-model-from-vllm-to-RTP-LLM)"
msgstr ""

#: ../../supported_models/support_new_models.md:14
msgid "How to Support a New Multimodal Large Language Model"
msgstr ""

#: ../../supported_models/support_new_models.md:16
msgid "To support a new multimodal large language model (MLLM) in RTP-LLM, there are several key components in addition to the standard LLM support:"
msgstr ""

#: ../../supported_models/support_new_models.md:19
msgid "**Register your new model as multimodal**: Extend `is_multimodal_model` in [model_config.py](http://gitlab.alibaba-inc.com/foundation_models/RTP-LLM/blob/0ab3f437aba729b348a683ab32b35b214456efc7/python/RTP-LLM/srt/configs/model_config.py#L561) to return `True` for your model."
msgstr ""

#: ../../supported_models/support_new_models.md:24
msgid "**Register a new chat-template** See [conversation.py](http://gitlab.alibaba-inc.com/foundation_models/RTP-LLM/blob/86a779dbe9e815c02f71ea82574608f6eae016b5/python/RTP-LLM/srt/conversation.py)"
msgstr ""

#: ../../supported_models/support_new_models.md:27
msgid "**Multimodal Data Processor**: Define a new `Processor` class that inherits from `BaseMultimodalProcessor` and register this processor as your model’s dedicated processor. See [multimodal_processor.py](http://gitlab.alibaba-inc.com/foundation_models/RTP-LLM/blob/main/python/RTP-LLM/srt/managers/multimodal_processor.py) for more details."
msgstr ""

#: ../../supported_models/support_new_models.md:33
msgid "**Handle Multimodal Tokens**: Implement a `pad_input_ids` function for your new model. In this function, multimodal tokens in the prompt should be expanded (if necessary) and padded with multimodal-data-hashes so that RTP-LLM can recognize different multimodal data with `RadixAttention`."
msgstr ""

#: ../../supported_models/support_new_models.md:38
msgid "**Adapt to Vision Attention**: Adapt the multi-headed `Attention` of ViT with RTP-LLM’s `VisionAttention`."
msgstr ""

#: ../../supported_models/support_new_models.md:41
msgid "You can refer to [Qwen2VL](http://gitlab.alibaba-inc.com/foundation_models/RTP-LLM/blob/main/python/RTP-LLM/srt/models/qwen2_vl.py) or other mllm implementations. These models demonstrate how to correctly handle both multimodal and textual inputs."
msgstr ""

#: ../../supported_models/support_new_models.md:44
msgid "You should test the new MLLM locally against Hugging Face models. See the [ `mmmu`](http://gitlab.alibaba-inc.com/foundation_models/RTP-LLM/tree/main/benchmark/mmmu) benchmark for an example."
msgstr ""

#: ../../supported_models/support_new_models.md:47
msgid "Test the Correctness"
msgstr ""

#: ../../supported_models/support_new_models.md:49
msgid "Interactive Debugging"
msgstr ""

#: ../../supported_models/support_new_models.md:51
msgid "For interactive debugging, compare the outputs of Hugging Face/Transformers and RTP-LLM. The following two commands should give the same text output and very similar prefill logits:"
msgstr ""

#: ../../supported_models/support_new_models.md:54
msgid "Get the reference output:"
msgstr ""

#: ../../supported_models/support_new_models.md:58
msgid "Get the RTP-LLM output:"
msgstr ""

#: ../../supported_models/support_new_models.md:63
msgid "Add the Model to the Test Suite"
msgstr ""

#: ../../supported_models/support_new_models.md:65
msgid "To ensure the new model is well maintained, add it to the test suite by including it in the `ALL_OTHER_MODELS` list in the [test_generation_models.py](http://gitlab.alibaba-inc.com/foundation_models/RTP-LLM/blob/main/test/srt/models/test_generation_models.py) file, test the new model on your local machine and report the results on demonstrative benchmarks (GSM8K, MMLU, MMMU, MMMU-Pro, etc.) in your PR."
msgstr ""

#: ../../supported_models/support_new_models.md:70
msgid "This is the command to test a new model on your local machine:"
msgstr ""

#: ../../supported_models/support_new_models.md:76
msgid "Port a Model from vLLM to RTP-LLM"
msgstr ""

#: ../../supported_models/support_new_models.md:78
msgid "The [vLLM Models Directory](https://github.com/vllm-project/vllm/tree/main/vllm/model_executor/models) is a valuable resource, as vLLM covers many models. RTP-LLM reuses vLLM’s interface and some layers, making it easier to port models from vLLM to RTP-LLM."
msgstr ""

#: ../../supported_models/support_new_models.md:82
msgid "To port a model from vLLM to RTP-LLM:"
msgstr ""

#: ../../supported_models/support_new_models.md:84
msgid "Compare these two files for guidance:"
msgstr ""

#: ../../supported_models/support_new_models.md:85
msgid "[RTP-LLM Llama Implementation](http://gitlab.alibaba-inc.com/foundation_models/RTP-LLM/blob/main/python/RTP-LLM/srt/models/llama.py)"
msgstr ""

#: ../../supported_models/support_new_models.md:86
msgid "[vLLM Llama Implementation](https://github.com/vllm-project/vllm/blob/main/vllm/model_executor/models/llama.py)"
msgstr ""

#: ../../supported_models/support_new_models.md:87
msgid "The major differences include:"
msgstr ""

#: ../../supported_models/support_new_models.md:88
msgid "**Replace vLLM’s `Attention` with `RadixAttention`** (ensure you pass `layer_id` to `RadixAttention`)."
msgstr ""

#: ../../supported_models/support_new_models.md:89
msgid "**Replace vLLM’s `LogitsProcessor` with RTP-LLM’s `LogitsProcessor`.**"
msgstr ""

#: ../../supported_models/support_new_models.md:90
msgid "**Replace the multi-headed `Attention` of ViT with RTP-LLM’s `VisionAttention`.**"
msgstr ""

#: ../../supported_models/support_new_models.md:91
msgid "**Replace other vLLM layers** (such as `RMSNorm`, `SiluAndMul`) with RTP-LLM layers."
msgstr ""

#: ../../supported_models/support_new_models.md:92
msgid "**Remove `Sample`.**"
msgstr ""

#: ../../supported_models/support_new_models.md:93
msgid "**Change the `forward()` functions** and add a `forward_batch()` method."
msgstr ""

#: ../../supported_models/support_new_models.md:94
msgid "**Add `EntryClass`** at the end."
msgstr ""

#: ../../supported_models/support_new_models.md:95
msgid "**Ensure that the new implementation uses only RTP-LLM components** and does not rely on any vLLM components."
msgstr ""

#: ../../supported_models/support_new_models.md:97
msgid "Note: make sure you add your new model to the supported models list in the supported models documentation."
msgstr ""

#: ../../supported_models/support_new_models.md:99
msgid "Registering an External Model Implementation"
msgstr ""

#: ../../supported_models/support_new_models.md:101
msgid "In addition to the methods above, you can register your new model with the `ModelRegistry` before launching the server. This allows you to integrate your model without modifying the source code."
msgstr ""

#: ../../supported_models/support_new_models.md:104
msgid "For example:"
msgstr ""

#: ../../supported_models/support_new_models.md:131
msgid "By following these guidelines, you can add support for new language models and multimodal large language models in RTP-LLM and ensure they are thoroughly tested and easily integrated into the system."
msgstr ""
