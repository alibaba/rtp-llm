# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2023-2025, RTP-LLM
# This file is distributed under the same license as the RTP-LLM package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: RTP-LLM 0.2.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-10-20 10:08+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../../supported_models/generative_models.md:1
msgid "Large Language Models"
msgstr ""

#: ../../supported_models/generative_models.md:3
msgid "These models accept text input and produce text output (e.g., chat completions). They are primarily large language models (LLMs), some with mixture-of-experts (MoE) architectures for scaling."
msgstr ""

#: ../../supported_models/generative_models.md:5
msgid "Example launch Command"
msgstr ""

#: ../../supported_models/generative_models.md:15
msgid "Supported models"
msgstr ""

#: ../../supported_models/generative_models.md:17
msgid "Below the supported models are summarized in a table."
msgstr ""

#: ../../supported_models/generative_models.md:19
msgid "If you are unsure if a specific architecture is implemented, you can search for it via GitHub. For example, to search for `Qwen3ForCausalLM`, use the expression:"
msgstr ""

#: ../../supported_models/generative_models.md:25
msgid "in the GitHub search bar."
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "Model Family (Variants)"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "Example HuggingFace Identifier"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "ModelType"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "Description"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "**DeepSeek** (v1, v2, v3/R1)"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "`deepseek-ai/DeepSeek-R1`"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "deepseek_v3"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "Series of advanced reasoning-optimized models (including a 671B MoE) trained with reinforcement learning; top performance on complex reasoning, math, and code tasks. [RTP-LLM provides Deepseek v3/R1 model-specific optimizations](../references/deepseek/reporter.md)"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "**DeepSeek** (v1, v2)"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "`deepseek-ai/DeepSeek-V2`"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "deepseek_v2"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "Series of advanced reasoning-optimized models (including a 671B MoE) trained with reinforcement learning; top performance on complex reasoning, math, and code tasks."
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "**Qwen** (3MoE, 2.5MoE, Coder)"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "`Qwen/Qwen3-30B-A3B`, `Qwen/Qwen3-Coder-480B-A35B-Instruct`"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "qwen_3_moe"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "Alibaba’s latest Qwen3Moe series for complex reasoning, language understanding, and generation tasks; Support for MoE variants along with previous generation 3, etc."
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "**Qwen** (3 series)"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "`Qwen/Qwen3-32B`"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "qwen_3"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "Alibaba’s latest Qwen3 series for complex reasoning, language understanding, and generation tasks; Support for dense variants along with previous generation 3,  etc."
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "**Qwen** (2.5, 2, 1.5, QWQ series)"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "`Qwen/Qwen2-72B`"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "qwen_2"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "Alibaba’s latest Qwen2 series for complex reasoning, language understanding, and generation tasks; Support fo dense along with previous generation 2.5, 2, 1.5, etc."
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "**Qwen** (1 series)"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "`Qwen/Qwen-72B`"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "qwen"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "Alibaba’s latest Qwen3 series for complex reasoning, language understanding, and generation tasks; Support for MoE variants along with previous generation 2.5, 2, etc."
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "**Llama** (2, 3.x, 4 series)"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "`meta-llama/Llama-4-Scout-17B-16E-Instruct`"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "llama"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "Meta’s open LLM series, spanning 7B to 400B parameters (Llama 2, 3, and new Llama 4) with well-recognized performance."
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "**Mistral** (Mixtral, NeMo, Small3)"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "`mistralai/Mistral-7B-Instruct-v0.2`"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "mistral"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "Open 7B LLM by Mistral AI with strong performance; extended into MoE (“Mixtral”) and NeMo Megatron variants for larger scale."
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "**Gemma** (v1, v2, v3)"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "`google/gemma-3-1b-it`"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "gemma"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "Google’s family of efficient multilingual models (1B–27B); Gemma 3 offers a 128K context window, and its larger (4B+) variants support vision input."
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "**Phi** (Phi-1.5, Phi-2, Phi-3, Phi-4, Phi-MoE series)"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "`microsoft/Phi-4-multimodal-instruct`, `microsoft/Phi-3.5-MoE-instruct`"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "phi"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "Microsoft’s Phi family of small models (1.3B–5.6B); Phi-4-multimodal (5.6B) processes text, images, and speech, Phi-4-mini is a high-accuracy text model and Phi-3.5-MoE is a mixture-of-experts model."
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "**DBRX** (Databricks)"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "`databricks/dbrx-instruct`"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "Dbrx"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "Databricks’ 132B-parameter MoE model (36B active) trained on 12T tokens; competes with GPT-3.5 quality as a fully open foundation model."
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "**ChatGLM2**"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "`zai-org/chatglm2-6b`"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "chat_glm_2"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "Zhipu AI’s bilingual chat model (6B) excelling at Chinese-English dialogue; fine-tuned for conversational quality and alignment."
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "**ChatGLM3**"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "`zai-org/chatglm3-6b`"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "chat_glm_3"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "**GLM4**"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "`zai-org/glm-4-9b-hf`"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "chat_glm_4"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "**InternLM 2** (7B, 20B)"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "`internlm/internlm2-7b`"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "internlm2"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "Next-gen InternLM (7B and 20B) from SenseTime, offering strong reasoning and ultra-long context support (up to 200K tokens)."
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "**Baichuan 2** (7B, 13B)"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "`baichuan-inc/Baichuan2-13B-Chat`"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "baichuan2"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "BaichuanAI’s second-generation Chinese-English LLM (7B/13B) with improved performance and an open commercial license."
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "**XVERSE**"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "`xverse/XVERSE-13B`"
msgstr ""

#: ../../supported_models/generative_models.md:0
msgid "Yuanxiang’s open LLM supporting ~40 languages; delivers 100B+ dense-level performance via expert routing."
msgstr ""
